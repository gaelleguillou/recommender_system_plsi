{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of PLSI algorithm using Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import findspark\n",
    "findspark.init(\"spark-2.2.3-bin-hadoop2.6\")\n",
    "import pyspark\n",
    "from numpy import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the PLSI algorithm on the Movielens dataset. To simplify our task, we will start by implementing the PLSI algorithm on a reduced version of the Movielens dataset (\"ratings_short\"), which contains 100 836 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_username</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>William</td>\n",
       "      <td>1768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>James</td>\n",
       "      <td>615</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>532</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>698</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id user_username  movie_id  rating\n",
       "0        2       William      1768       1\n",
       "1        3         James       615       3\n",
       "2        7        Joseph        82       3\n",
       "3        7        Joseph       532       3\n",
       "4        8        Thomas       698       3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data = pd.read_csv(\"ratings.csv\")\n",
    "ratings_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of the dataset :** \n",
    "- userId, to characterize the users \n",
    "- movieId, to characterize the movies\n",
    "- rating : the rating of the user to the corresponding movie. Ratings are going from 1 to 5 but here we will only use the seen / not seen information to provide movie recommendations.  \n",
    "- timestamp : we will not be using this column\n",
    "\n",
    "More information about the movies are available in the \"movies.csv\" dataset : the movieId gives us access to the corresponding movie information such as the title and the genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"movies.csv\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####MORE DESCRIPTIONS ON THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to implement the PLSI algorithm in Spark, we will need to transform the dataset into an RDD, and then perform pyspark operations on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,William,1768,1',\n",
       " '3,James,615,3',\n",
       " '7,Joseph,82,3',\n",
       " '7,Joseph,532,3',\n",
       " '8,Thomas,698,3',\n",
       " '10,Robert,1693,3',\n",
       " '11,Edward,615,1',\n",
       " '18,David,1,3',\n",
       " '18,David,28,3',\n",
       " '18,David,1596,5']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile(\"ratings.csv\")\n",
    "\n",
    "#Remove header line \n",
    "header = rdd.first()\n",
    "rdd = rdd.filter(lambda x: x != header)\n",
    "\n",
    "rdd.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Probabilistic Latent Semantic Indexing algorithm (PLSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PLSI algorithm that we will implement here is based on Das description of the Google News recommendation system. The algorithm is based on the following model : \n",
    "- u (users) and s (movies) are random variables \n",
    "- The relationship between users and movies is learned by modeling the joint distribution of users and items as a mixture distribution \n",
    "- To capture this relationship, we introduce a hidden variable z (latent variable), that kind of represents user communities (same preferences) and movie communities (sames genres). \n",
    "\n",
    "All in all, we try to compute the following probability for each (user, movie) couple : p(s|u) = sum(p(s|z)p(z|u)), which is the probability for a given user to see a given movie. This is obtained by summing for each community the probability for a movie s to be seen given a community z times the probability to be in the community z given a user u. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going through the algorithm : main steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INITIALISATION**\n",
    "\n",
    "**E-STEP - Compute q( z | (u,s) ) : the probability that the (user, movie) couple belongs to the class z**\n",
    "This step is first initialized at random :\n",
    "- To each couple (u,s), assign each possible community \n",
    "- Ex with number of classes = 2 : the lines (Marie, Star Wars) and (Gaëlle, Matrix) will give (Marie, Star Wars, 1), (Marie, Star Wars, 2), (Gaëlle, Matrix, 1), (Gaëlle, Matrix, 2)\n",
    "- To each line, assign a random probability. This random probability corresponds to q*( z | (u,s) ). For example if I have (Marie, Star Wars, 1, 0.3), then the probability that the couple (Marie, Star Wars) is in class 1 is 0.3. \n",
    "\n",
    "LogLik = 0\n",
    "\n",
    "**ITERATION**\n",
    "\n",
    "**M-STEP - Compute p(s|z) and p(z|u) based on q( z | (u,s) )**\n",
    "- Compute p(s | z) :  sum the probas associated to every couple (s,z) and divide it by the sum of probas associated to this z\n",
    "- Compute p(z | u) : sum the probas associated to every couple (u,z) and divide by the sum of probas associated to this u\n",
    "\n",
    "**E-STEP - Compute new q( z | (u,s) ) = p(s|z)p(z|u) / ∑p(s|z)p(z|u)**\n",
    "- For each (u,s,z), compute p(s | z) * p(z | u)\n",
    "- For each (u,s), compute ∑ p(s | z)* p(z | u) (summing over z)     ***(this corresponds to p(s|u))***\n",
    "- For each (u,s,z), compute p(s|z)p(z|u) / ∑p(s|z)p(z|u)             ***(this corresponds to the new q( z | (u,s) )***\n",
    "\t    \n",
    "**Update LogLik** = sum( log( ∑ p(s | z) * p(z | u))) = sum( log (p(s | u))\n",
    "\n",
    "**Iterate again until LogLik converges** : this means that it has reached its maximum and we have found the best estimation of p(z | u) and p(s | z).\n",
    "\t    \n",
    "**We can now predict the probability that Gaëlle will watch Star Wars** :\n",
    "p(Star Wars | Gaëlle) = p( 1 | Gaëlle) * p(Star Wars |1) + p(2 | Gaëlle) * p(Star Wars | 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only (user, movie) information : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda line : line.split(',')).map(lambda line : line[0] + ',' + line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,1768',\n",
       " '3,615',\n",
       " '7,82',\n",
       " '7,532',\n",
       " '8,698',\n",
       " '10,1693',\n",
       " '11,615',\n",
       " '18,1',\n",
       " '18,28',\n",
       " '18,1596']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation of q : (first E-Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To each couple (u,s), assign each possible community z : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_z = 3 #number of classes\n",
    "classes = sc.parallelize(range(nb_z))\n",
    "classes.collect()\n",
    "rdd = rdd.cartesian(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2,1768', 0),\n",
       " ('3,615', 0),\n",
       " ('7,82', 0),\n",
       " ('7,532', 0),\n",
       " ('8,698', 0),\n",
       " ('10,1693', 0),\n",
       " ('11,615', 0),\n",
       " ('18,1', 0),\n",
       " ('18,28', 0),\n",
       " ('18,1596', 0)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To each line, assign a random probability :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = rdd.map(lambda x : (x, np.random.rand()))\n",
    "q = q.map(lambda x : (x[0][0].split(','), x[0][1], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['2', '1768'], 0, 0.0022266067292384673),\n",
       " (['3', '615'], 0, 0.6952350116531781),\n",
       " (['7', '82'], 0, 0.7036829130103541),\n",
       " (['7', '532'], 0, 0.9535123375904958),\n",
       " (['8', '698'], 0, 0.05904050841113617),\n",
       " (['10', '1693'], 0, 0.4191670103214322),\n",
       " (['11', '615'], 0, 0.4316767734336888),\n",
       " (['18', '1'], 0, 0.9857750440664248),\n",
       " (['18', '28'], 0, 0.8333981157619267),\n",
       " (['18', '1596'], 0, 0.48291949455861816)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One iteration step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M-STEP - Compute p(s|z) and p(z|u) based on q( z | (u,s) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute p(s | z) : sum the probas associated to every couple (s,z) and divide it by the sum of probas associated to this z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ_probas = q.map(lambda x: ((x[0][1], x[1]), x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsz = SZ_probas.reduceByKey(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_probas = q.map(lambda x: (x[1], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nz = Z_probas.reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsz = Nsz.map(lambda x : (x[0][1], (x[0][0], x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psz = Nsz.join(Nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psz = Psz.map(lambda x : ((x[1][0][0], x[0]), x[1][0][1] / x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute p(z | u) : sum the probas associated to every couple (u,z) and divide by the sum of probas associated to this u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZU_probas = q.map(lambda x: ((x[0][0], x[1]), x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nzu = ZU_probas.reduceByKey(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_probas = q.map(lambda x: (x[0][0], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nu = U_probas.reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nzu = Nzu.map(lambda x : (x[0][0], (x[0][1], x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pzu = Nzu.join(Nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pzu = Pzu.map(lambda x : ((x[1][0][0], x[0]), x[1][0][1] / x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E-STEP - Compute new q( z | (u,s) ) = p(s|z)p(z|u) / ∑p(s|z)p(z|u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each (u,s,z), compute p(s | z) * p(z | u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, '10'), 0.3333333333333333),\n",
       " ((0, '10'), 0.3333333333333333),\n",
       " ((2, '10'), 0.3333333333333333),\n",
       " ((1, '44'), 0.3333333333333333),\n",
       " ((0, '44'), 0.3333333333333333),\n",
       " ((2, '44'), 0.3333333333333333),\n",
       " ((1, '54'), 0.3333333333333333),\n",
       " ((0, '54'), 0.3333333333333333),\n",
       " ((2, '54'), 0.3333333333333333),\n",
       " ((1, '102'), 0.3333333333333333)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pzu.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1', 0), 0.005685184977099493),\n",
       " (('1596', 0), 0.012360966432698435),\n",
       " (('130', 0), 0.03684078110308122),\n",
       " (('68', 0), 0.03806300471276274),\n",
       " (('517', 0), 0.04728579674309403),\n",
       " (('598', 0), 0.02886330455948453),\n",
       " (('1856', 0), 0.0033575666175042276),\n",
       " (('564', 0), 0.027436949758408432),\n",
       " (('1293', 0), 0.006810781885253489),\n",
       " (('2767', 0), 0.005893079737151274)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psz.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pzu = Pzu.map(lambda x : (x[0][0], (x[0][1], x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psz = Psz.map(lambda x : (x[0][1], (x[0][0], x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('10', 0.3333333333333333)),\n",
       " (0, ('10', 0.3333333333333333)),\n",
       " (2, ('10', 0.3333333333333333)),\n",
       " (1, ('44', 0.3333333333333333)),\n",
       " (0, ('44', 0.3333333333333333)),\n",
       " (2, ('44', 0.3333333333333333)),\n",
       " (1, ('54', 0.3333333333333333)),\n",
       " (0, ('54', 0.3333333333333333)),\n",
       " (2, ('54', 0.3333333333333333)),\n",
       " (1, ('102', 0.3333333333333333))]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pzu.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('1', 0.005685184977099493)),\n",
       " (0, ('1596', 0.012360966432698435)),\n",
       " (0, ('130', 0.03684078110308122)),\n",
       " (0, ('68', 0.03806300471276274)),\n",
       " (0, ('517', 0.04728579674309403)),\n",
       " (0, ('598', 0.02886330455948453)),\n",
       " (0, ('1856', 0.0033575666175042276)),\n",
       " (0, ('564', 0.027436949758408432)),\n",
       " (0, ('1293', 0.006810781885253489)),\n",
       " (0, ('2767', 0.005893079737151274))]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psz.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "PzuPsz = Pzu.join(Psz).map(lambda x : ((x[1][0][0], x[1][1][0]), (x[0], x[1][0][1]*x[1][1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('10', '1'), (0, 0.0018950616590331642)),\n",
       " (('10', '1596'), (0, 0.0041203221442328115)),\n",
       " (('10', '130'), (0, 0.01228026036769374)),\n",
       " (('10', '68'), (0, 0.01268766823758758)),\n",
       " (('10', '517'), (0, 0.015761932247698007)),\n",
       " (('10', '598'), (0, 0.009621101519828177)),\n",
       " (('10', '1856'), (0, 0.0011191888725014091)),\n",
       " (('10', '564'), (0, 0.009145649919469477)),\n",
       " (('10', '1293'), (0, 0.0022702606284178296)),\n",
       " (('10', '2767'), (0, 0.0019643599123837577))]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PzuPsz.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each (u,s), compute ∑ p(s | z)* p(z | u) (summing over z) (this corresponds to p(s|u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "SumPzuPsz = PzuPsz.map(lambda x : (x[0], x[1][1])).reduceByKey(lambda x,y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('10', '770'), 0.041272879250374275),\n",
       " (('10', '1097'), 0.009934157939033121),\n",
       " (('44', '2498'), 0.011040179950712641),\n",
       " (('44', '1550'), 0.0036719624506974646),\n",
       " (('54', '770'), 0.041272879250374275),\n",
       " (('54', '1097'), 0.009934157939033121),\n",
       " (('102', '770'), 0.041272879250374275),\n",
       " (('102', '1097'), 0.009934157939033121),\n",
       " (('112', '2498'), 0.011040179950712641),\n",
       " (('112', '1550'), 0.0036719624506974646)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SumPzuPsz.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each (u,s,z), compute p(s|z)p(z|u) / ∑p(s|z)p(z|u) (this corresponds to the new q( z | (u,s) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = PzuPsz.join(SumPzuPsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('10', '770'), ((0, 0.01344994304525593), 0.041272879250374275)),\n",
       " (('10', '770'), ((1, 0.013911468102559173), 0.041272879250374275)),\n",
       " (('10', '770'), ((2, 0.013911468102559173), 0.041272879250374275)),\n",
       " (('54', '1097'), ((0, 0.0015842162183411067), 0.009934157939033121)),\n",
       " (('54', '1097'), ((1, 0.004174970860346007), 0.009934157939033121)),\n",
       " (('54', '1097'), ((2, 0.004174970860346007), 0.009934157939033121)),\n",
       " (('102', '770'), ((0, 0.01344994304525593), 0.041272879250374275)),\n",
       " (('102', '770'), ((1, 0.013911468102559173), 0.041272879250374275)),\n",
       " (('102', '770'), ((2, 0.013911468102559173), 0.041272879250374275)),\n",
       " (('190', '770'), ((0, 0.01344994304525593), 0.041272879250374275))]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = q1.map(lambda x : (x[0], x[1][0][0], x[1][0][1]/x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('10', '770'), 0, 0.3258784773328835),\n",
       " (('10', '770'), 1, 0.3370607613335583),\n",
       " (('10', '770'), 2, 0.3370607613335583),\n",
       " (('54', '1097'), 0, 0.15947161581923636),\n",
       " (('54', '1097'), 1, 0.4202641920903818),\n",
       " (('54', '1097'), 2, 0.4202641920903818),\n",
       " (('102', '770'), 0, 0.3258784773328835),\n",
       " (('102', '770'), 1, 0.3370607613335583),\n",
       " (('102', '770'), 2, 0.3370607613335583),\n",
       " (('190', '770'), 0, 0.3258784773328835)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update LogLik = sum( log( ∑ p(s | z) * p(z | u))) = sum( log (p(s | u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230.48638694217286"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogLik = SumPzuPsz.map(lambda x : x[1]).sum()\n",
    "LogLik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of the iteration step "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
